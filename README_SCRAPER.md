# ğŸ•·ï¸ Web Scraper AvancÃ© - Version 2.0

Scraper web professionnel avec gestion avancÃ©e des cas bloquants et export multi-formats (Markdown + Word).

---

## ğŸ“‹ FonctionnalitÃ©s

### âœ… Gestion des Cas Bloquants

Le scraper intÃ¨gre de nombreuses techniques pour contourner les protections courantes :

| Protection | Solution ImplÃ©mentÃ©e |
|------------|---------------------|
| **Anti-bot dÃ©tection** | User-Agent rotation, suppression des marqueurs automation |
| **Cloudflare / WAF** | DÃ©tection + mode stealth, headers personnalisÃ©s |
| **Rate limiting** | Retry automatique avec backoff exponentiel |
| **Timeouts** | Timeouts configurables + gestion d'erreurs robuste |
| **SSL/TLS** | DÃ©sactivation de la vÃ©rification pour les certificats invalides |
| **Pop-ups / Cookies** | Fermeture automatique des banniÃ¨res courantes |
| **Lazy loading** | Scroll automatique pour charger le contenu dynamique |
| **JavaScript** | Support complet via Selenium + attente du chargement |
| **Redirections** | Gestion automatique |
| **Captcha** | DÃ©tection (nÃ©cessite intervention manuelle) |

### ğŸ“¤ Export Multi-formats

- **Markdown (.md)** : Format lÃ©ger et portable
- **Word (.docx)** : Format professionnel avec mise en forme

### ğŸ¯ Extraction ComplÃ¨te

Le scraper extrait :
- âœ… **Texte principal** : Contenu nettoyÃ© et structurÃ©
- âœ… **Tableaux** : Conversion automatique en format Markdown/Word
- âœ… **Images** : TÃ©lÃ©chargement local + intÃ©gration dans les exports
- âœ… **Liens** : Extraction de tous les hyperliens
- âœ… **MÃ©tadonnÃ©es** : Title, description, Open Graph, etc.

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8 ou supÃ©rieur
- Google Chrome installÃ© (pour Selenium)

### Ã‰tapes

1. **Installer les dÃ©pendances** :
   ```bash
   pip install -r requirements_scraper.txt
   ```

2. **VÃ©rifier l'installation** :
   ```bash
   python web_scraper_advanced.py
   ```

---

## ğŸ’» Utilisation

### Mode Interactif (RecommandÃ©)

```bash
python web_scraper_advanced.py
```

Le script vous guidera Ã  travers les options :
1. Entrer l'URL Ã  scraper
2. Choisir si vous voulez tÃ©lÃ©charger les images
3. SÃ©lectionner les formats d'export (MD, Word, ou les deux)
4. Options avancÃ©es (mode headless, scroll, proxy)

### Exemple d'exÃ©cution

```
======================================================================
           WEB SCRAPER AVANCÃ‰ - Version 2.0
======================================================================

ğŸŒ Entrez l'URL du site Ã  scraper: example.com/article

ğŸ“‹ OPTIONS:
TÃ©lÃ©charger les images? (o/N): o
Exporter en Markdown? (O/n): o
Exporter en Word? (O/n): o

Options avancÃ©es? (o/N): n

ğŸš€ DÃ©marrage du scraping...

[INFO] Driver Chrome crÃ©Ã© avec succÃ¨s
[INFO] Tentative 1/3 : Chargement de https://example.com/article
[INFO] âœ“ Page chargÃ©e avec succÃ¨s
[INFO] Scroll vers le bas pour charger le contenu dynamique...
[INFO] Extraction du contenu...
[INFO] âœ“ 3 tableau(x) extrait(s)
[INFO] âœ“ 15 image(s) trouvÃ©e(s)
[INFO] âœ“ 45 lien(s) extrait(s)
[INFO] TÃ©lÃ©chargement de 15 images...
Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:08<00:00,  1.75it/s]
[INFO] âœ“ 15 image(s) tÃ©lÃ©chargÃ©e(s)
[INFO] GÃ©nÃ©ration du fichier Markdown: scraped_content/example_com_20250111_143022.md
[INFO] âœ“ Fichier Markdown gÃ©nÃ©rÃ©
[INFO] GÃ©nÃ©ration du fichier Word: scraped_content/example_com_20250111_143022.docx
[INFO] âœ“ Fichier Word gÃ©nÃ©rÃ©

âœ… SCRAPING RÃ‰USSI!

ğŸ“ RÃ©sultats dans le dossier: scraped_content/
   - Texte extrait: 12450 caractÃ¨res
   - Tableaux: 3
   - Images: 15
   - Liens: 45
```

---

## ğŸ› ï¸ Utilisation Programmatique

Vous pouvez Ã©galement utiliser le scraper dans vos propres scripts Python :

```python
from web_scraper_advanced import AdvancedWebScraper, ScraperConfig

# Configuration personnalisÃ©e
config = ScraperConfig()
config.HEADLESS = True  # Mode sans interface
config.SCROLL_TO_BOTTOM = True  # Activer le scroll
config.PAGE_LOAD_TIMEOUT = 45  # Timeout personnalisÃ©

# CrÃ©er le scraper
scraper = AdvancedWebScraper(config)

# Scraper une URL
content = scraper.scrape(
    url="https://example.com",
    download_images=True,
    export_formats=['md', 'docx']  # ou ['md'] ou ['docx']
)

# AccÃ©der au contenu
print(f"Titre: {content['title']}")
print(f"Texte: {content['text'][:200]}...")
print(f"Nombre d'images: {len(content['images'])}")
```

---

## âš™ï¸ Configuration AvancÃ©e

Le fichier `web_scraper_advanced.py` contient une classe `ScraperConfig` que vous pouvez personnaliser :

```python
class ScraperConfig:
    # Liste de User-Agents (rotation automatique)
    USER_AGENTS = [...]

    # Timeouts (secondes)
    PAGE_LOAD_TIMEOUT = 30
    IMPLICIT_WAIT = 10
    EXPLICIT_WAIT = 15
    SCROLL_PAUSE_TIME = 2

    # Retry
    MAX_RETRIES = 3
    RETRY_DELAY = 2
    BACKOFF_FACTOR = 2

    # Dossiers de sortie
    OUTPUT_DIR = "scraped_content"
    IMAGES_DIR = "images"

    # Options de scraping
    HEADLESS = True  # Mode sans interface
    DISABLE_IMAGES = False  # DÃ©sactiver pour performance
    SCROLL_TO_BOTTOM = True  # Pour lazy loading

    # Ã‰lÃ©ments Ã  supprimer du HTML
    UNWANTED_TAGS = ["script", "style", "nav", "footer", ...]
    UNWANTED_CLASSES = ["advertisement", "ad", "popup", ...]
```

---

## ğŸ“‚ Structure des Fichiers de Sortie

AprÃ¨s l'exÃ©cution, vous trouverez :

```
scraped_content/
â”œâ”€â”€ example_com_20250111_143022.md        # Export Markdown
â”œâ”€â”€ example_com_20250111_143022.docx      # Export Word
â””â”€â”€ images/                                # Images tÃ©lÃ©chargÃ©es
    â”œâ”€â”€ image_1.jpg
    â”œâ”€â”€ image_2.png
    â””â”€â”€ ...
```

---

## ğŸ¨ Formats d'Export

### Markdown (.md)

Structure du fichier Markdown :

```markdown
# Titre de la Page

**URL source**: https://example.com
**Date d'extraction**: 2025-01-11T14:30:22

---

## ğŸ“‹ MÃ©tadonnÃ©es
- **description**: Description de la page
- **keywords**: mot1, mot2, mot3
- **author**: Auteur

---

## ğŸ“„ Contenu Textuel
[Texte principal de la page]

---

## ğŸ“Š Tableaux (2)
### Tableau 1
| Colonne 1 | Colonne 2 |
|-----------|-----------|
| DonnÃ©e 1  | DonnÃ©e 2  |

---

## ğŸ–¼ï¸ Images (10)
### Image 1: Description
![Description](images/image_1.jpg)

---

## ğŸ”— Liens Extraits (45)
- [Texte du lien](https://url.com)

---

**Fin du document**
```

### Word (.docx)

Le fichier Word contient :
- Titre centrÃ© en style Heading 0
- MÃ©tadonnÃ©es formatÃ©es
- Texte avec paragraphes
- Tableaux avec style "Light Grid Accent 1"
- Images intÃ©grÃ©es (largeur max 6 pouces)
- Liens sous forme de liste Ã  puces

---

## ğŸ› RÃ©solution de ProblÃ¨mes

### Erreur : "Chrome driver not found"

**Solution** : Le script tÃ©lÃ©charge automatiquement le driver via `webdriver-manager`. Assurez-vous que Chrome est installÃ©.

```bash
# Ubuntu/Debian
sudo apt install chromium-browser

# macOS
brew install --cask google-chrome

# Windows
TÃ©lÃ©charger depuis: https://www.google.com/chrome/
```

### Erreur : "Timeout lors du chargement"

**Solutions** :
1. Augmenter les timeouts dans `ScraperConfig`
2. VÃ©rifier votre connexion internet
3. Le site peut Ãªtre temporairement indisponible

```python
config.PAGE_LOAD_TIMEOUT = 60  # Augmenter Ã  60 secondes
```

### DÃ©tection de Cloudflare / Captcha

**SymptÃ´me** : Le log indique "âš ï¸ Blocage dÃ©tectÃ©: Cloudflare"

**Solutions** :
1. Activer le mode non-headless pour voir ce qui se passe :
   ```python
   config.HEADLESS = False
   ```

2. Installer `undetected-chromedriver` (dÃ©commenter dans requirements) :
   ```bash
   pip install undetected-chromedriver
   ```

   Puis modifier le code pour l'utiliser :
   ```python
   import undetected_chromedriver as uc
   driver = uc.Chrome(options=options)
   ```

3. Utiliser un proxy / VPN si le site bloque votre IP

4. Pour les Captchas : rÃ©solution manuelle nÃ©cessaire (mode non-headless)

### Images non tÃ©lÃ©chargÃ©es

**Causes possibles** :
- Images en lazy loading : activez `SCROLL_TO_BOTTOM = True`
- URLs relatives mal formÃ©es : le script tente de les corriger automatiquement
- Images protÃ©gÃ©es : certaines images peuvent nÃ©cessiter l'authentification

### Contenu incomplet

**Solutions** :
1. Augmenter le dÃ©lai de scroll :
   ```python
   config.SCROLL_PAUSE_TIME = 5  # Attendre 5 secondes entre les scrolls
   ```

2. VÃ©rifier que JavaScript est activÃ© :
   ```python
   config.ENABLE_JAVASCRIPT = True
   ```

3. Le site peut charger le contenu via AJAX aprÃ¨s interaction utilisateur

---

## ğŸ“Š Logging

Tous les Ã©vÃ©nements sont enregistrÃ©s dans `scraper.log` avec diffÃ©rents niveaux :

```
2025-01-11 14:30:22 - WebScraper - INFO - Driver Chrome crÃ©Ã© avec succÃ¨s
2025-01-11 14:30:25 - WebScraper - INFO - âœ“ Page chargÃ©e avec succÃ¨s
2025-01-11 14:30:26 - WebScraper - WARNING - âš ï¸ Blocage dÃ©tectÃ©: Cloudflare
2025-01-11 14:30:30 - WebScraper - INFO - âœ“ 15 image(s) tÃ©lÃ©chargÃ©e(s)
```

Consultez ce fichier pour dÃ©boguer les problÃ¨mes.

---

## ğŸ” ConsidÃ©rations LÃ©gales et Ã‰thiques

âš ï¸ **Important** :

1. **Respectez les conditions d'utilisation** : VÃ©rifiez les CGU du site avant de scraper
2. **Consultez robots.txt** : `https://example.com/robots.txt`
3. **Rate limiting** : Ne surchargez pas les serveurs (le scraper implÃ©mente dÃ©jÃ  des dÃ©lais)
4. **Copyright** : Le contenu scrapÃ© peut Ãªtre protÃ©gÃ© par copyright
5. **Usage personnel** : Utilisez ce scraper de maniÃ¨re responsable

---

## ğŸ¤ Contribution

AmÃ©liorations possibles :
- [ ] Support de proxies multiples avec rotation
- [ ] IntÃ©gration d'`undetected-chromedriver` par dÃ©faut
- [ ] Support de rÃ©solution de Captcha via services tiers
- [ ] Export en PDF
- [ ] Mode batch (scraper plusieurs URLs)
- [ ] Interface graphique (GUI)
- [ ] Support de l'authentification (login)
- [ ] Scraping de sites avec pagination

---

## ğŸ“ Notes Techniques

### Architecture

Le scraper est organisÃ© en classes modulaires :

- **`ScraperConfig`** : Configuration centralisÃ©e
- **`AdvancedWebDriver`** : Gestion du navigateur Selenium
- **`ContentExtractor`** : Extraction et parsing du contenu
- **`ImageDownloader`** : TÃ©lÃ©chargement des images
- **`MarkdownExporter`** : Export Markdown
- **`WordExporter`** : Export Word
- **`AdvancedWebScraper`** : Orchestrateur principal

### DÃ©pendances ClÃ©s

- **Selenium 4.15+** : Automation du navigateur
- **BeautifulSoup 4.12+** : Parsing HTML
- **python-docx 1.1+** : GÃ©nÃ©ration de documents Word
- **requests 2.31+** : TÃ©lÃ©chargement d'images
- **tqdm 4.66+** : Progress bars

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. Consultez le fichier `scraper.log`
2. VÃ©rifiez la section "RÃ©solution de ProblÃ¨mes" ci-dessus
3. Ouvrez une issue sur le dÃ©pÃ´t GitHub (si applicable)

---

## ğŸ“œ Licence

Ce code est fourni Ã  des fins Ã©ducatives. Utilisez-le de maniÃ¨re responsable et conformÃ©ment aux lois applicables.

---

**Version** : 2.0
**DerniÃ¨re mise Ã  jour** : Janvier 2025
**Auteur** : Claude AI
